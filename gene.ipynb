{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c25ea5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c235997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tanish don't jump me. It is sample data. We need to replace with actual datasets\n",
    "df = pd.read_csv('optimizedextra.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d8403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization? idk ts is lowkai hard\n",
    "def codonize(seq):\n",
    "    return [seq[i:i+3] for i in range(0, len(seq), 3) if len(seq[i:i+3]) == 3]\n",
    "#define the codons???\n",
    "all_codons = set()\n",
    "for _, row in df.iterrows():\n",
    "    all_codons.update(codonize(row['original']))\n",
    "    all_codons.update(codonize(row['optimized']))\n",
    "\n",
    "codon2idx = {codon: idx+4 for idx, codon in enumerate(sorted(all_codons))}\n",
    "codon2idx['<pad>'] = 0\n",
    "codon2idx['<sos>'] = 1\n",
    "codon2idx['<eos>'] = 2\n",
    "codon2idx['<unk>'] = 3\n",
    "idx2codon = {idx: codon for codon, idx in codon2idx.items()}\n",
    "vocab_size = len(codon2idx)\n",
    "\n",
    "#encoder, decoder stuff\n",
    "def encode(seq):\n",
    "    return [codon2idx.get(c, codon2idx['<unk>']) for c in codonize(seq)]\n",
    "\n",
    "def decode(indices):\n",
    "    return ''.join([idx2codon[i] for i in indices if i not in (0, 1, 2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c9467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.pairs = []\n",
    "        for _, row in df.iterrows():\n",
    "            src = [codon2idx['<sos>']] + encode(row['original']) + [codon2idx['<eos>']]\n",
    "            trg = [codon2idx['<sos>']] + encode(row['optimized'])\n",
    "            self.pairs.append((src, trg))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pairs[idx]\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    max_src = max(len(s) for s in src_batch)\n",
    "    max_trg = max(len(t) for t in trg_batch)\n",
    "    src_padded = [s + [codon2idx['<pad>']] * (max_src - len(s)) for s in src_batch]\n",
    "    trg_padded = [t + [codon2idx['<pad>']] * (max_trg - len(t)) for t in trg_batch]\n",
    "    return torch.tensor(src_padded), torch.tensor(trg_padded)\n",
    "\n",
    "dataset = GeneDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gooning to seq2seq encoder and decoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=codon2idx['<pad>'])\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=codon2idx['<pad>'])\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hid_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.embedding(input)\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        return self.fc_out(output.squeeze(1)), hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.3):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        vocab_size = self.decoder.fc_out.out_features\n",
    "        outputs = torch.zeros(batch_size, trg_len, vocab_size)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = trg[:, 0]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if random.random() < teacher_forcing_ratio else top1\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a591cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Synthetic-Gene-Generator/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.2137\n",
      "Epoch 2, Loss: 4.1788\n",
      "Epoch 3, Loss: 4.1305\n",
      "Epoch 4, Loss: 4.0532\n",
      "Epoch 5, Loss: 3.9424\n",
      "Epoch 6, Loss: 3.7971\n",
      "Epoch 7, Loss: 3.6879\n",
      "Epoch 8, Loss: 3.6564\n",
      "Epoch 9, Loss: 3.6138\n",
      "Epoch 10, Loss: 3.5936\n",
      "Epoch 11, Loss: 3.6054\n",
      "Epoch 12, Loss: 3.5798\n",
      "Epoch 13, Loss: 3.5908\n",
      "Epoch 14, Loss: 3.5861\n",
      "Epoch 15, Loss: 3.5834\n",
      "Epoch 16, Loss: 3.5780\n",
      "Epoch 17, Loss: 3.5789\n",
      "Epoch 18, Loss: 3.5678\n",
      "Epoch 19, Loss: 3.5789\n",
      "Epoch 20, Loss: 3.5750\n",
      "Epoch 21, Loss: 3.5585\n",
      "Epoch 22, Loss: 3.5742\n",
      "Epoch 23, Loss: 3.5757\n",
      "Epoch 24, Loss: 3.5739\n",
      "Epoch 25, Loss: 3.5641\n",
      "Epoch 26, Loss: 3.5731\n",
      "Epoch 27, Loss: 3.5602\n",
      "Epoch 28, Loss: 3.5740\n",
      "Epoch 29, Loss: 3.5688\n",
      "Epoch 30, Loss: 3.5574\n"
     ]
    }
   ],
   "source": [
    "#training za gooner\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "enc = Encoder(vocab_size, 32, 64).to(device)\n",
    "dec = Decoder(vocab_size, 32, 64).to(device)\n",
    "model = Seq2Seq(enc, dec).to(device)\n",
    "optimzer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=codon2idx['<pad>'])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, trg in dataloader:\n",
    "        src,trg = src.to(device), trg.to(device)\n",
    "        optimzer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output = output[:, 1:].reshape(-1, vocab_size)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        optimzer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714a1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gooner prediction\n",
    "def predict(model, seq):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src = [codon2idx['<sos>']] + encode(seq) + [codon2idx['<eos>']]\n",
    "        src_tensor = torch.tensor([src]).to(device)\n",
    "        hidden, cell = model.encoder(src_tensor)\n",
    "        input = torch.tensor([codon2idx['<sos>']]).to(device)\n",
    "        output_seq = []\n",
    "        for _ in range(30):\n",
    "            output, hidden, cell = model.decoder(input, hidden, cell)\n",
    "            top1 = output.argmax(1).item()\n",
    "            if top1 == codon2idx['<eos>']:\n",
    "                break\n",
    "            output_seq.append(top1)\n",
    "            input = torch.tensor([top1]).to(device)\n",
    "        return decode(output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c9524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ATGC\n",
      "Synthetic:  ATGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTGCTG\n"
     ]
    }
   ],
   "source": [
    "#input\n",
    "user_input = input(\"Original: \")\n",
    "print(\"Original: \", user_input)\n",
    "print(\"Synthetic: \", predict(model, user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e808475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the FASTA file\n",
    "with open(\"trimmed_file.fasta\", \"r\") as infile:\n",
    "    lines = [line.strip() for line in infile if line.strip()]\n",
    "\n",
    "# Step 2: Remove first 1000 sequences (i.e. 2000 lines)\n",
    "trimmed_lines = lines[:-2883]\n",
    "\n",
    "# Step 3: Write the remaining sequences to a new FASTA file\n",
    "with open(\"trimmed_file.fasta\", \"w\") as outfile:\n",
    "    for line in trimmed_lines:\n",
    "        outfile.write(line + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
